import json
import logging
import time
from pathlib import Path
from typing import List, Tuple, Dict, Any, Optional

from openai import OpenAI
from telethon.events import NewMessage

from utils.utils import (
    model,
    max_token,
    read_existing_conversation,
    num_tokens_from_messages,
    sys_mess,
)

from functions.additional_func import search as web_search
from rag.search import search as rag_search

client = OpenAI()
Prompt = List[dict]

# ===============================================================
# SETTINGS
# ===============================================================

WINDOW_SIZE = 12
SUMMARY_MAX_TOKENS = 300
RESPONSE_MAX_TOKENS = 800

WAIT_WEB_CONFIRM_STATE = "__WAIT_WEB_SEARCH_CONFIRM__"

YES_WORDS = {"Ð´Ð°", "Ð´Ð°Ð²Ð°Ð¹", "Ð°Ð³Ð°", "Ð¸Ñ‰Ð¸", "Ð½Ð°Ð¹Ð´Ð¸", "Ð¾Ðº"}
NO_WORDS = {"Ð½ÐµÑ‚", "Ð½Ðµ Ð½Ð°Ð´Ð¾", "Ð½Ðµ Ð½ÑƒÐ¶Ð½Ð¾"}

FILE_REQUEST_WORDS = {
    "ÑÐºÐ¸Ð½ÑŒ",
    "Ð¿Ñ€Ð¸ÑˆÐ»Ð¸",
    "Ð¿ÐµÑ€ÐµÑˆÐ»Ð¸",
    "Ð´Ð°Ð¹ Ñ„Ð°Ð¹Ð»",
    "Ð¾Ñ‚Ð¿Ñ€Ð°Ð²ÑŒ Ñ„Ð°Ð¹Ð»",
    "Ð´Ð°Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚",
    "Ð¿Ñ€Ð¸ÑˆÐ»Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚",
    "Ð¿ÐµÑ€ÐµÑˆÐ»Ð¸ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚",
    "ÑÐºÐ¸Ð½ÑŒ Ð¿Ð°Ð¼ÑÑ‚ÐºÑƒ",
    "Ð²Ñ‹Ð´Ð°Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚",
    "pdf",
}


BASE_PROJECT_DIR = Path(__file__).resolve().parents[2]


# ===============================================================
# HELPERS
# ===============================================================

def trim_prompt_window(prompt: Prompt) -> Prompt:
    system_msgs = [m for m in prompt if m["role"] == "system"]
    dialog_msgs = [m for m in prompt if m["role"] != "system"]

    if len(dialog_msgs) <= WINDOW_SIZE:
        return prompt

    dialog_msgs = dialog_msgs[-WINDOW_SIZE:]
    return system_msgs + dialog_msgs


def should_keep_message(text: str) -> bool:
    if not text:
        return False

    trash = {
        "Ð¾Ðº",
        "Ð°Ð³Ð°",
        "Ð¿Ð¾Ð½ÑÐ»",
        "Ð¿Ð¾Ð½ÑÐ»Ð°",
        "ÑÐ¿Ð°ÑÐ¸Ð±Ð¾",
        "Ð¾ÐºÐµÐ¹",
        "Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾",
        "ÑÑÐ½Ð¾",
    }

    t = text.lower().strip()
    return t not in trash


def is_affirmative(text: str) -> bool:
    return any(w in text.lower() for w in YES_WORDS)


def is_negative(text: str) -> bool:
    return any(w in text.lower() for w in NO_WORDS)


def request_documents(text: str) -> bool:
    text = text.lower()
    return any(patt in text for patt in FILE_REQUEST_WORDS)


# ===============================================================
# RAG
# ===============================================================

def _format_rag_chunks(
    chunks: List[Dict[str, Any]],
    max_sources: int = 3,
    max_chars: int = 2500,
) -> Tuple[str, List[Dict[str, Any]]]:

    if not chunks:
        return "", []

    lines: List[str] = []
    sources: List[Dict[str, Any]] = []
    used = set()
    total_len = 0

    for rank, ch in enumerate(chunks[:max_sources], start=1):
        text = (ch.get("text") or "").strip()
        if not text:
            continue

        source_file = ch.get("source_file") or ch.get("source")
        page = ch.get("page")

        snippet = text[:800]
        header = f"[{rank}] Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº: {source_file}"
        if page:
            header += f", ÑÑ‚Ñ€. {page}"

        block = f"{header}\n{snippet}"

        if total_len + len(block) > max_chars:
            break

        lines.append(block)
        total_len += len(block)

        key = (source_file, page)
        if key not in used:
            used.add(key)
            sources.append(
                {
                    "source_file": source_file,
                    "page": page,
                }
            )

    return "\n\n---\n\n".join(lines), sources


def _build_sources_hint(sources: List[Dict[str, Any]]) -> str:
    if not sources:
        return ""

    lines = []
    for s in sources:
        name = s.get("source_file") or "Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½Ð¸Ð¹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚"
        page = s.get("page")
        if page:
            name += f", ÑÑ‚Ñ€. {page}"
        lines.append(f"- {name}")

    return "\n".join(lines)


def try_rag(query: str) -> Optional[Dict[str, Any]]:
    try:
        chunks = rag_search(query)

        if not chunks:
            return None

        formatted, sources = _format_rag_chunks(chunks)
        if not formatted:
            return None

        return {
            "formatted": formatted,
            "sources": sources,
        }

    except Exception:
        logging.exception("RAG SEARCH ERROR")
        return None


# ===============================================================
# CHAT
# ===============================================================

async def start_and_check(event: NewMessage, message: str, chat_id: int):

    session, filename, prompt = read_existing_conversation(str(chat_id))

    if not any(m["role"] == "system" for m in prompt):
        prompt.insert(0, {"role": "system", "content": sys_mess})

    text = message.strip()

    # ===================================================
    # SEND DOCUMENT REQUEST
    # ===================================================

    if request_documents(text):

        sources = session.get("last_rag_sources", [])

        if not sources:
            return filename, [
                {
                    "role": "assistant",
                    "content": "Ð£ Ð¼ÐµÐ½Ñ ÐµÑ‰Ñ‘ Ð½ÐµÑ‚ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°, Ð¸Ð· ÐºÐ°ÐºÐ¾Ð³Ð¾ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð° Ð¾Ñ‚Ð¿Ñ€Ð°Ð²Ð»ÑÑ‚ÑŒ Ñ„Ð°Ð¹Ð». Ð—Ð°Ð´Ð°Ð¹Ñ‚Ðµ Ð²Ð¾Ð¿Ñ€Ð¾Ñ ÑÐ½Ð°Ñ‡Ð°Ð»Ð°.",
                }
            ]

        attachments = []
        for s in sources:
            rel_path = s.get("source_file")
            if not rel_path:
                continue

            full_path = BASE_PROJECT_DIR / rel_path
            if full_path.exists():
                attachments.append(full_path)

        if not attachments:
            return filename, [
                {
                    "role": "assistant",
                    "content": "ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð½Ð°Ð¹Ñ‚Ð¸ Ñ„Ð°Ð¹Ð»Ñ‹ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² Ð½Ð° ÑÐµÑ€Ð²ÐµÑ€Ðµ.",
                }
            ]

        # ÐžÑ‚Ð¿Ñ€Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð°Ð¹Ð»Ñ‹
        for f in attachments:
            await event.client.send_file(
                chat_id,
                file=f,
                caption=f"Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº: {f.name}",
            )

        return filename, []


    # ===================================================
    # NORMAL QUESTION
    # ===================================================

    rag_payload = try_rag(text)

    if rag_payload:

        rag_text = rag_payload["formatted"]
        rag_sources = rag_payload["sources"]

        session["state"] = None
        session["last_rag_sources"] = rag_sources

        sources_hint = _build_sources_hint(rag_sources)

        system_content = (
            "Ð¢Ñ‹ ÐºÐ¾Ñ€Ð¿Ð¾Ñ€Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ ÑÐµÑ‚Ð¸ Â«Ð§ÐµÑ‚Ñ‹Ñ€Ðµ Ð›Ð°Ð¿Ñ‹Â».\n"
            "ÐžÑ‚Ð²ÐµÑ‡Ð°Ð¹ ÑÑ‚Ñ€Ð¾Ð³Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð½Ð° Ð±Ð°Ð·Ðµ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð½Ð¸Ð¶Ðµ.\n\n"
            "=== Ð’ÐÐ£Ð¢Ð Ð•ÐÐÐ¯Ð¯ Ð‘ÐÐ—Ð ===\n"
            f"{rag_text}\n"
            "=== ÐšÐžÐÐ•Ð¦ ===\n\n"
        )

        if sources_hint:
            system_content += (
                "Ð’ ÐºÐ¾Ð½Ñ†Ðµ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð´Ð¾Ð±Ð°Ð²ÑŒ:\n"
                "ðŸ“š Ð˜ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¸:\n"
                f"{sources_hint}"
            )

        prompt.insert(1, {"role": "system", "content": system_content})
        prompt.append({"role": "user", "content": text})

    else:
        session["state"] = WAIT_WEB_CONFIRM_STATE
        session["last_rag_query"] = text

        prompt.append(
            {
                "role": "assistant",
                "content": (
                    "Ð’Ð¾ Ð²Ð½ÑƒÑ‚Ñ€ÐµÐ½Ð½ÐµÐ¹ Ð±Ð°Ð·Ðµ Ð·Ð½Ð°Ð½Ð¸Ð¹ Ð½ÐµÑ‚ Ñ‚Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ð¸ Ð¿Ð¾ ÑÑ‚Ð¾Ð¼Ñƒ Ð²Ð¾Ð¿Ñ€Ð¾ÑÑƒ.\n"
                    "Ð˜ÑÐºÐ°Ñ‚ÑŒ Ð¾Ñ‚Ð²ÐµÑ‚ Ð² Ð¸Ð½Ñ‚ÐµÑ€Ð½ÐµÑ‚Ðµ?"
                ),
            }
        )

        save_session(filename, session, prompt)
        return filename, prompt

    prompt = trim_prompt_window(prompt)

    tokens = num_tokens_from_messages(prompt)

    if tokens > max_token - 500:
        await create_summary_and_reset(prompt, filename)
        session, filename, prompt = read_existing_conversation(str(chat_id))

        if not any(m["role"] == "system" for m in prompt):
            prompt.insert(0, {"role": "system", "content": sys_mess})

        prompt.append({"role": "user", "content": text})

    return filename, prompt


# ===============================================================
# SUMMARY
# ===============================================================

async def create_summary_and_reset(prompt: Prompt, filename: str):
    try:
        dialog_only = [m for m in prompt if m["role"] != "system"]

        summary_prompt = [
            {
                "role": "system",
                "content": "Ð¡Ð¾Ð¶Ð¼Ð¸ Ð´Ð¸Ð°Ð»Ð¾Ð³ Ð² ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð¸Ð· 3â€“5 Ð¿Ñ€ÐµÐ´Ð»Ð¾Ð¶ÐµÐ½Ð¸Ð¹.",
            },
            {"role": "user", "content": json.dumps(dialog_only, ensure_ascii=False)},
        ]

        completion = client.chat.completions.create(
            model=model,
            messages=summary_prompt,
            max_tokens=SUMMARY_MAX_TOKENS,
            temperature=0.2,
        )

        summary = completion.choices[0].message.content.strip()

        new_prompt = [
            {"role": "system", "content": sys_mess},
            {"role": "system", "content": f"Ð ÐµÐ·ÑŽÐ¼Ðµ Ð¿Ñ€Ð¾ÑˆÐ»Ð¾Ð³Ð¾ Ð´Ð¸Ð°Ð»Ð¾Ð³Ð°: {summary}"},
        ]

        save_session(filename, {"messages": new_prompt}, new_prompt)

    except Exception as e:
        logging.error(f"SUMMARY ERROR: {e}")


# ===============================================================
# SAVE
# ===============================================================

def save_session(filename: str, session: dict, prompt: Prompt):
    try:
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(
                {
                    **session,
                    "messages": prompt,
                },
                f,
                ensure_ascii=False,
                indent=2,
            )
    except Exception as e:
        logging.error(f"SAVE SESSION ERROR: {e}")
