import subprocess
import logging
import base64

from openai import OpenAI

from src.utils import model, sys_mess

client = OpenAI()

# =====================================================
# –ö–æ–º–∞–Ω–¥–Ω–∞—è –æ–±–æ–ª–æ—á–∫–∞ (bash)
# =====================================================

async def bash(command: str) -> str:
    try:
        if not command:
            return "‚ùå –ö–æ–º–∞–Ω–¥–∞ –Ω–µ —É–∫–∞–∑–∞–Ω–∞."

        result = subprocess.check_output(
            command,
            shell=True,
            stderr=subprocess.STDOUT
        )
        return result.decode("utf-8")[:4000]

    except subprocess.CalledProcessError as e:
        return f"–û—à–∏–±–∫–∞ –∫–æ–º–∞–Ω–¥—ã:\n{e.output.decode('utf-8')[:4000]}"


# =====================================================
# ‚úÖ REAL INTERNET SEARCH
# =====================================================

async def search(query: str) -> str:
    """
    –ù–∞—Å—Ç–æ—è—â–∏–π live-–ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ —á–µ—Ä–µ–∑ OpenAI web_search.
    """
    try:
        if not query:
            return "–í–≤–µ–¥–∏—Ç–µ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞."

        response = client.responses.create(
            model="gpt-4.1-mini",
            tools=[{"type": "web_search"}],
            input=f"–ù–∞–π–¥–∏ –∞–∫—Ç—É–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –æ—Ç–≤–µ—Ç—å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ —Ç–æ—á–Ω–æ:\n{query}",
            max_output_tokens=700,
            temperature=0.2
        )

        text = response.output_text.strip()

        if not text:
            return "üîé –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–∏—Å–∫–∞."

        return text

    except Exception as e:
        logging.error(f"Web search error: {e}")
        return "‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ."


# =====================================================
# IMAGE GENERATION
# =====================================================

async def generate_image(prompt: str) -> str:
    try:
        if not prompt:
            prompt = "–ú–∏–ª–æ–µ –¥–æ–º–∞—à–Ω–µ–µ –∂–∏–≤–æ—Ç–Ω–æ–µ, –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —Å—Ç–∏–ª—å"

        result = client.images.generate(
            model="gpt-image-1",
            prompt=prompt,
            size="1024x1024"
        )

        return result.data[0].url

    except Exception as e:
        logging.error(f"Image generation error: {e}")
        return "‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."


# =====================================================
# IMAGE ANALYSIS (VISION)
# =====================================================

async def analyze_image_with_gpt(
    image_bytes: bytes,
    user_prompt: str | None = None
) -> str:
    try:
        prompt = user_prompt or "–û–ø–∏—à–∏, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏."

        image_b64 = base64.b64encode(image_bytes).decode("utf-8")

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": sys_mess},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_b64}"
                            },
                        },
                    ]
                }
            ],
            max_tokens=500,
            temperature=0.2,
        )

        return response.choices[0].message.content.strip()

    except Exception as e:
        logging.error(f"Vision analyze error: {e}")
        return "‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è."
