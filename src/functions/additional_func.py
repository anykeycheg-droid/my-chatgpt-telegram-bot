import asyncio
import base64
import logging

from openai import OpenAI

from src.utils import model, sys_mess

client = OpenAI()


# ==============================
# BASH
# ==============================

async def bash(cmd: str) -> str:
    """
    –í—ã–ø–æ–ª–Ω–∏—Ç—å shell-–∫–æ–º–∞–Ω–¥—É –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ –∏ –≤–µ—Ä–Ω—É—Ç—å –µ—ë –≤—ã–≤–æ–¥.
    """
    cmd = (cmd or "").strip()
    if not cmd:
        return "‚ùå –ù–µ —É–∫–∞–∑–∞–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ –¥–ª—è /bash."

    try:
        proc = await asyncio.create_subprocess_shell(
            cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.STDOUT,
        )
        stdout, _ = await proc.communicate()
        output = stdout.decode("utf-8", errors="ignore").strip()

        if not output:
            output = "‚úÖ –ö–æ–º–∞–Ω–¥–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –±–µ–∑ –≤—ã–≤–æ–¥–∞."

        return f"üíª bash$ {cmd}\n\n{output}"

    except Exception as e:
        logging.exception("BASH ERROR")
        return f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∫–æ–º–∞–Ω–¥—ã: {e}"


# ==============================
# WEB SEARCH
# ==============================

async def search(query: str) -> str:
    """
    –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å).
    –í–∞–∂–Ω–æ: –æ—Ç–≤–µ—á–∞–µ—Ç –ø–æ-—Ä—É—Å—Å–∫–∏ –∏ –≤ –±—Ä–µ–Ω–¥–∏–Ω–≥–µ ¬´–ß–µ—Ç—ã—Ä–µ –õ–∞–ø—ã ‚Äî –∏ –Ω–µ —Ç–æ–ª—å–∫–æ¬ª.
    """
    query = (query or "").strip()
    if not query:
        return "‚ùå –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏ –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø–æ–∏—Å–∫–∞."

    try:
        system_prompt = (
            "–¢—ã ‚Äî –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç —Å–µ—Ç–∏ –∑–æ–æ–º–∞–≥–∞–∑–∏–Ω–æ–≤ ¬´–ß–µ—Ç—ã—Ä–µ –õ–∞–ø—ã ‚Äî –∏ –Ω–µ —Ç–æ–ª—å–∫–æ¬ª. "
            "–û—Ç–≤–µ—á–∞–π –ø–æ-—Ä—É—Å—Å–∫–∏, –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É. "
            "–ï—Å–ª–∏ –∑–∞–ø—Ä–æ—Å —Å–≤—è–∑–∞–Ω —Å –¥–æ–º–∞—à–Ω–∏–º–∏ –∂–∏–≤–æ—Ç–Ω—ã–º–∏, –∑–æ–æ—Ç–æ–≤–∞—Ä–∞–º–∏ –∏–ª–∏ —É—Ö–æ–¥–æ–º, "
            "–∏—Å–ø–æ–ª—å–∑—É–π —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –±—Ä–µ–Ω–¥–∞. –ï—Å–ª–∏ —Ç–µ–º–∞ –∏–Ω–∞—è, –≤—Å—ë —Ä–∞–≤–Ω–æ –ø–æ–º–æ–≥–∏, "
            "–Ω–æ –º–æ–∂–µ—à—å –Ω–µ–Ω–∞–≤—è–∑—á–∏–≤–æ –Ω–∞–ø–æ–º–Ω–∏—Ç—å –æ –±—Ä–µ–Ω–¥–µ."
        )

        completion = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": system_prompt},
                {
                    "role": "user",
                    "content": f"–ù–∞–π–¥–∏ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ –∏ –∫—Ä–∞—Ç–∫–æ –æ—Ç–≤–µ—Ç—å –Ω–∞ –∑–∞–ø—Ä–æ—Å: {query}",
                },
            ],
            max_tokens=800,
            temperature=0.2,
        )

        return completion.choices[0].message.content.strip()

    except Exception as e:
        logging.exception("SEARCH ERROR")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–∏—Å–∫–∞: {e}"


# ==============================
# IMAGE GENERATION
# ==============================

async def generate_image(prompt: str) -> bytes:
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ OpenAI.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –±–∞–π—Ç—ã –∫–∞—Ä—Ç–∏–Ω–∫–∏ (PNG/JPEG) –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —á–µ—Ä–µ–∑ Telethon.
    """
    if not prompt:
        prompt = (
            "–ú–∏–ª–æ–µ –¥–æ–º–∞—à–Ω–µ–µ –∂–∏–≤–æ—Ç–Ω–æ–µ –≤ —Ñ–∏—Ä–º–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ —Å–µ—Ç–∏ –∑–æ–æ–º–∞–≥–∞–∑–∏–Ω–æ–≤ "
            "¬´–ß–µ—Ç—ã—Ä–µ –õ–∞–ø—ã ‚Äî –∏ –Ω–µ —Ç–æ–ª—å–∫–æ¬ª"
        )

    # OpenAI Images API: –ø–æ–ª—É—á–∞–µ–º –∫–∞—Ä—Ç–∏–Ω–∫—É –≤ base64 –∏ –¥–µ–∫–æ–¥–∏—Ä—É–µ–º –≤ bytes
    result = client.images.generate(
        model="gpt-image-1",
        prompt=prompt,
        size="1024x1024",
        response_format="b64_json",
    )

    image_b64 = result.data[0].b64_json
    return base64.b64decode(image_b64)


# ==============================
# IMAGE ANALYSIS (VISION)
# ==============================

async def analyze_image_with_gpt(
    image_bytes: bytes,
    user_prompt: str | None = None
) -> str:
    try:
        prompt = user_prompt or "–û–ø–∏—à–∏, —á—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–æ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ."

        image_b64 = base64.b64encode(image_bytes).decode("utf-8")

        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": sys_mess},
                {
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt},
                        {
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{image_b64}"
                            },
                        },
                    ],
                },
            ],
            max_tokens=500,
        )

        return response.choices[0].message.content

    except Exception as e:
        logging.exception("VISION ERROR")
        return f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}"
